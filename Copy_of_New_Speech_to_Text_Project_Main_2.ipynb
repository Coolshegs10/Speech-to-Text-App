{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coolshegs10/Speech-to-Text-App/blob/main/Copy_of_New_Speech_to_Text_Project_Main_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAZOVH4MAr5h"
      },
      "source": [
        "Step 1. Install the Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nIj1kJ5lQIbK"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# Upload the raw audio file\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0ZvCRIt8QP8U"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# Access the uploaded file\n",
        "# file_name = next(iter(uploaded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8EHPSTtQkvz"
      },
      "outputs": [],
      "source": [
        "# ipd.Audio(new_audio, rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "S29RQkEDTq7U",
        "outputId": "35a128e7-318c-4a1a-97a8-d4f909c74c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.35.2\n",
            "Uninstalling transformers-4.35.2:\n",
            "  Successfully uninstalled transformers-4.35.2\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-4.36.2\n"
          ]
        }
      ],
      "source": [
        "# IT STARTS HERE\n",
        "\n",
        "!pip uninstall transformers  -y\n",
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcycQKpJ59cI"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZQT8O2hSZ79I",
        "outputId": "6b196a81-43dd-4c1c-f48b-3d9b2c2762fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj71ulTaUJlV",
        "outputId": "6bc88e39-f16a-4cff-8cab-8ea259a4557f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Rl0n--tsSjbF",
        "outputId": "f83306e0-1852-48a5-8eb5-9723bf75691d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.36.2\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "pip show transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8HaoIVZ9Srvp",
        "outputId": "88cf592a-8d94-4c35-d0a8-d6aabb617441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers --upgrade-strategy eager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nFBc3imOSyJo",
        "outputId": "028651df-bfe9-440a-c5da-0e18936eb8c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.36.2\n",
            "Uninstalling transformers-4.36.2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/transformers-cli\n",
            "    /usr/local/lib/python3.10/dist-packages/transformers-4.36.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/transformers/*\n",
            "Proceed (Y/n)? "
          ]
        }
      ],
      "source": [
        "pip uninstall transformers && pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N9eK5x6sTuge"
      },
      "outputs": [],
      "source": [
        "!python3 -m pip cache purge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VPUlJQuvYYQJ"
      },
      "outputs": [],
      "source": [
        "!pip install torch_sdpa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "Fxri1VcPZD8M"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NV-L_m1DQMJO"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torchaudio\n",
        "import torch\n",
        "\n",
        "# Check and set the device (GPU if available, CPU otherwise)\n",
        "processing_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0tWN2HII6kGV"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "import torch\n",
        "import soundfile as sf\n",
        "\n",
        "# Let's import necessary audio processing libraries\n",
        "import os\n",
        "import torchaudio\n",
        "\n",
        "# Let's specify the device based on availability of GPU/CPU, enabling an optimized processing based on the available hardware\n",
        "processing_device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIvvqhgK80M5"
      },
      "source": [
        "# Method 1: Wav2Vec2.0 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kbKdSnId7nY3"
      },
      "outputs": [],
      "source": [
        "# The major models under Wav2Vec2.0 include:\n",
        "# wav2vec2_model_name = \"facebook/wav2vec2-base-960h\" # 360MB\n",
        "# wav2vec2_model_name = \"facebook/wav2vec2-large-960h-lv60-self\" # pretrained 1.26GB\n",
        "wav2vec2_model_name = \"jonatasgrosman/wav2vec2-large-xlsr-53-english\" # English-only, 1.26GB\n",
        "# wav2vec2_model_name = \"jonatasgrosman/wav2vec2-large-xlsr-53-arabic\" # Arabic-only, 1.26GB\n",
        "# wav2vec2_model_name = \"jonatasgrosman/wav2vec2-large-xlsr-53-spanish\" # Spanish-only, 1.26GB\n",
        "\n",
        "\n",
        "# my project focused on a Enghlish speech to text conversion, hence:\n",
        "wav2vec2_processor = Wav2Vec2Processor.from_pretrained(wav2vec2_model_name)\n",
        "wav2vec2_model = Wav2Vec2ForCTC.from_pretrained(wav2vec2_model_name).to(processing_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXZrpZJEQMER"
      },
      "outputs": [],
      "source": [
        "# Supporting Libariries for Audio files\n",
        "import librosa # librosa is a Python package for music and audio processing\n",
        "import librosa.display\n",
        "import IPython.display as ipd  # to play the audio signal\n",
        "import matplotlib.pyplot as plt #plot the audio signal in time domain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIIeU0ca1oba"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import librosa\n",
        "import io\n",
        "import tempfile\n",
        "\n",
        "# audio_url = \"http://www.fit.vutbr.cz/~motlicek/sympatex/f2bjrop1.0.wav\"\n",
        "audio_url = \"http://www.fit.vutbr.cz/~motlicek/sympatex/f2bjrop1.0.wav\"\n",
        "\n",
        "\n",
        "# Download the audio file\n",
        "response = requests.get(audio_url)\n",
        "\n",
        "# Create a temporary file and write the audio data\n",
        "with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
        "    temp_file.write(response.content)\n",
        "    temp_file.seek(0)\n",
        "\n",
        "    # Load the audio file using librosa\n",
        "    x, sr = librosa.load(temp_file.name)\n",
        "\n",
        "# Play the audio using IPython display\n",
        "ipd.Audio(x, rate=sr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-v2WncbvqWsc"
      },
      "outputs": [],
      "source": [
        "# Let's calculate the time domain analaysis of the audio file\n",
        "\n",
        "plt.figure(figsize=(14, 5)) # this is the variable to change the rnage on the x and y axis\n",
        "plt.grid(True) # now the grid is enabled\n",
        "\n",
        "#  Let's plot the audio signal\n",
        "librosa.display.waveshow(x) #it takes one argument\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Time Domain Analysis of the Audio file\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBI-N3blQ5KL"
      },
      "outputs": [],
      "source": [
        "# Let's determine the duration of the audio file\n",
        "y=len(x) #number of sample x\n",
        "print(y)\n",
        "y1=sr #sampling frequency sr\n",
        "print(y1)\n",
        "y=len(x)\n",
        "duration_of_sound=y/y1\n",
        "print(duration_of_sound, \"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVLwSH-F2IlH"
      },
      "outputs": [],
      "source": [
        "# Let's load the audio file\n",
        "speech, sr = torchaudio.load(audio_url)\n",
        "speech = speech.squeeze()\n",
        "sr, speech.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1BA-rivwpLn"
      },
      "outputs": [],
      "source": [
        "# Now, let's resample the audio sampling form it's initial rate to 1600\n",
        "resampler = torchaudio.transforms.Resample(sr, 16000)\n",
        "speech = resampler(speech)\n",
        "speech.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGgpSeSVD37B"
      },
      "outputs": [],
      "source": [
        "# Now, let's tokenize the wav file\n",
        "input_values = wav2vec2_processor(speech, return_tensors=\"pt\", sampling_rate=16000)[\"input_values\"].to(processing_device)\n",
        "input_values.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu9ZXuNdFxBB"
      },
      "outputs": [],
      "source": [
        "# Next, let's perform inference\n",
        "logits = wav2vec2_model(input_values)[\"logits\"]\n",
        "logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsQ9m2moGgNB"
      },
      "outputs": [],
      "source": [
        "# Let's use argmax to find the predicted IDs\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "predicted_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTbfn-70Gj_9"
      },
      "outputs": [],
      "source": [
        "# Now, let's decode the IDs to text\n",
        "wav2vec2_transcription = wav2vec2_processor.decode(predicted_ids[0])\n",
        "wav2vec2_transcription.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvAZDLcWPuBQ"
      },
      "source": [
        "# Method 2: Whisper Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFSDD19EXG4w"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkN71xuo6UFR"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FdL6sr6N_15E"
      },
      "outputs": [],
      "source": [
        "# Since this is a English based STT project, we chose the English-only medium model\n",
        "whisper_model_name = \"openai/whisper-medium.en\" # Engllish-only, ~3.06 GB\n",
        "\n",
        "whisper_processor = WhisperProcessor.from_pretrained(whisper_model_name)\n",
        "whisper_model = WhisperForConditionalGeneration.from_pretrained(whisper_model_name).to(processing_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg_W0j-qccyX"
      },
      "outputs": [],
      "source": [
        "# Use response.content directly without temporary file\n",
        "x, sr = librosa.load(io.BytesIO(response.content), sr=sr)\n",
        "input_features = whisper_processor(x, sampling_rate=16000, return_tensors=\"pt\").input_features.to(processing_device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKgJ8TT4er30"
      },
      "outputs": [],
      "source": [
        "forced_decoder_ids = whisper_processor.get_decoder_prompt_ids(language= \"english\", task=\"transcribe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SuUvN_ClrLw"
      },
      "outputs": [],
      "source": [
        "forced_decoder_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA6XfKNDB_3d"
      },
      "outputs": [],
      "source": [
        "input_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNAmLPKlnSvM"
      },
      "outputs": [],
      "source": [
        "predicted_ids = whisper_model.generate(input_features, forced_decoder_ids=forced_decoder_ids)\n",
        "predicted_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXsNWvPvdqYq"
      },
      "outputs": [],
      "source": [
        "whisper_transcription1 = whisper_processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "whisper_transcription1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1VfcVKzf1uy"
      },
      "outputs": [],
      "source": [
        "whisper_transcription_2 = whisper_processor.batch_decode(predicted_ids, skip_special_tokens=False)\n",
        "whisper_transcription_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMNFROu4xzEG"
      },
      "source": [
        "# Part 2: System Performance Calculation  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8RFH6x35FZ7"
      },
      "outputs": [],
      "source": [
        "# To calculate the wer, we need to use a ground truth that will serve as the original transcript\n",
        "\n",
        "# Here's the trancription to be used as the ground transcription\n",
        "transcript = \"Wanted, Chief Justice of the Massachusetts Supreme Court. In April, the SJC's current leader, Edward Hennessey, reaches the mandatory retirement age of 70, and the successor is\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnU7jrnd7CcC"
      },
      "outputs": [],
      "source": [
        "# Now let's preprocess our trancription to get it ready for the calculation\n",
        "\n",
        "import re\n",
        "\n",
        "def process_text(transcript):\n",
        "  # Let's convert it to lowercase first\n",
        "  transcript = transcript.lower()\n",
        "\n",
        "  # Let's reove special characters and punctuations\n",
        "  transcript = re.sub(r'[^a-zA-Z0-9\\s]','', transcript)\n",
        "\n",
        "  # let's tokenize the transcription by splitting the texts into words\n",
        "  tokens = transcript.split()\n",
        "\n",
        "  return tokens\n",
        "\n",
        "# Let's check if it was preprocessed successfully\n",
        "preprocessed_transcript = process_text(transcript)\n",
        "\n",
        "# print the preprocessed text\n",
        "print(preprocessed_transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNYkDrHWQ1W5"
      },
      "outputs": [],
      "source": [
        "type(preprocessed_transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JzhHBBsl87t"
      },
      "outputs": [],
      "source": [
        "print(transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b73Afp1QWWO"
      },
      "outputs": [],
      "source": [
        "print(preprocessed_transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYCY3Lc382rr"
      },
      "outputs": [],
      "source": [
        "pip install dill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQo9ys_DpX_w"
      },
      "outputs": [],
      "source": [
        "type(wav2vec2_transcription)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqliG9iOpgxF"
      },
      "outputs": [],
      "source": [
        "type(whisper_transcription_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKjUtFZCxmNm"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pk163caC7z9Y"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade evaluate jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdtoUF-t71PQ"
      },
      "outputs": [],
      "source": [
        "from evaluate import load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB6geCAsPOpF"
      },
      "outputs": [],
      "source": [
        "print(wav2vec2_transcription)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pTSHO7mOlAP"
      },
      "outputs": [],
      "source": [
        "print(whisper_transcription1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30LmPlL1PYAa"
      },
      "outputs": [],
      "source": [
        "ref_words = transcript\n",
        "hyp_words = wav2vec2_transcription\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeasfO3ZTt9K"
      },
      "outputs": [],
      "source": [
        "type(whisper_transcription1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0uIqpwMKJvd"
      },
      "outputs": [],
      "source": [
        "wer_metric = load(\"wer\")\n",
        "\n",
        "wer = wer_metric.compute(references=[ref_words], predictions=[hyp_words])\n",
        "\n",
        "print(wer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6vdWEZHqIIy"
      },
      "outputs": [],
      "source": [
        "# We need to convert the whisper_transaction to str from a list so we can perform the wer\n",
        "whisper_string = ''.join(whisper_transcription1)\n",
        "print(whisper_string)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D5bkyNVRpzb"
      },
      "outputs": [],
      "source": [
        "type(whisper_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di0JYkQ2E9In"
      },
      "outputs": [],
      "source": [
        "wer_metric = load(\"wer\")\n",
        "\n",
        "wer = wer_metric.compute(references=[ref_words], predictions=[whisper_string])\n",
        "\n",
        "print(wer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHMuXQ_nCY99"
      },
      "outputs": [],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THU6mv-xHsm8"
      },
      "source": [
        "# Section 3: Raw record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6zYweoSCbmT"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKtT7WDfDqix"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqI-RyJhEGnB"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from pydub import AudioSegment\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcPakV7dEwua"
      },
      "outputs": [],
      "source": [
        "# Upload the raw audio file\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPwCvK7oEzS1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Access the uploaded file\n",
        "file_name = next(iter(uploaded))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggnc2ct9E3wx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert the uploaded audio file to AudioSegment\n",
        "audio_data = BytesIO(uploaded[file_name])\n",
        "audio_record = AudioSegment.from_file(audio_data, format=\"aac\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwNTufi3E7Bl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Export the audio to WAV format\n",
        "new_audio = 'new_audio.wav'\n",
        "audio_record.export(new_audio, format=\"wav\")\n",
        "\n",
        "print(f\"Conversion completed. WAV file saved as {new_audio}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxAcFQ-bHFur"
      },
      "outputs": [],
      "source": [
        "ipd.Audio(new_audio, rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsdDMnKcI5Op"
      },
      "outputs": [],
      "source": [
        "audio_data = open('new_audio.wav', 'rb').read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a63mORV7K5Nv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Let's determine the duration of the audio file\n",
        "y=len(audio_data) #number of sample x\n",
        "print(y)\n",
        "y1=sr #sampling frequency sr\n",
        "print(y1)\n",
        "y=len(audio_data)\n",
        "duration_of_sound=y/y1\n",
        "print(duration_of_sound, \"seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNMtAAN2NUdG"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Load the audio file\n",
        "import torchaudio\n",
        "from torchaudio.transforms import Resample\n",
        "\n",
        "# Load the audio file\n",
        "audio_path = 'new_audio.wav'\n",
        "speech, sr = torchaudio.load(audio_path)\n",
        "speech = speech.squeeze()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-SEaHW9NhxN"
      },
      "outputs": [],
      "source": [
        "# Step 2: Resample the audio to 16,000 Hz\n",
        "resampler = Resample(sr, 16000)\n",
        "speech_resampled = resampler(speech)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9FQ4-GdNnFY"
      },
      "outputs": [],
      "source": [
        "# Step 3: Prepare the audio for transcription with Whisper model\n",
        "# Assuming 'whisper_processor' and 'processing_device' are initialized\n",
        "\n",
        "# Tokenize the resampled audio\n",
        "input_values = whisper_processor(speech_resampled, sampling_rate=16000, return_tensors=\"pt\").input_features.to(processing_device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtXu33eWNzDO"
      },
      "outputs": [],
      "source": [
        "# Step 4: Perform inference (transcription) with the Whisper model\n",
        "# Assuming 'whisper_model' is initialized\n",
        "logits = whisper_model(input_values)[\"logits\"]\n",
        "# Process logits further if necessary to get the transcription result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNAzaEyQNe4S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7652bPXLqis"
      },
      "outputs": [],
      "source": [
        "# import speech_recognition as sr\n",
        "\n",
        "# recognizer = sr.Recognizer()\n",
        "\n",
        "''' recording the sound '''\n",
        "\n",
        "# with sr.AudioFile(\"./sample_audio/speech.wav\") as source:\n",
        "    #recorded_audio = recognizer.listen(source)\n",
        "    #print(\"Done recording\")\n",
        "\n",
        "''' Recorgnizing the Audio '''\n",
        "#try:\n",
        "    #print(\"Recognizing the text\")\n",
        "    #text = recognizer.recognize_google(\n",
        "            #recorded_audio,\n",
        "            #language=\"en-US\"\n",
        "        #)\n",
        "    #print(\"Decoded Text : {}\".format(text))\n",
        "\n",
        "#except Exception as ex:\n",
        "    #print(ex)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1xMJmU4RRRIsaEgiZfnzWfVXML1203ZL0",
      "authorship_tag": "ABX9TyPPciWrbiM64dnqMuvDDTST",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}